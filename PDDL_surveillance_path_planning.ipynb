{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d366a6b3",
   "metadata": {},
   "source": [
    "#### The code is expanding the work available in: https://github.com/pucrs-automated-planning/pddl-parser , and; Specific snippets (for heuristics and informed (Dijkstra, A*, Greedy Best First) and uninformed (DFS, BFS) search algorithms) can be also mutated from: https://github.com/APLA-Toolbox/PythonPDDL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12871f04",
   "metadata": {},
   "source": [
    "#### Check URL: https://github.com/remykarem/py2pddl for dynamic PDDL-based planning (Dynamic Python to Dynamic PDDL regeneration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67bfb068",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install a pip package (e.g., numpy) in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596eaec",
   "metadata": {},
   "source": [
    "## PDDL Parser (only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4e0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## running the PDDL.py main file from the terminal using python\n",
    "#!python PDDL.py # examples/dwr/dwr.pddl examples/dwr/pb1.pddl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c42a2",
   "metadata": {},
   "source": [
    "## PDDL Planner (baseline BFS planner):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366483f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -B planner.py examples/dinner/dinner.pddl examples/dinner/pb1.pddl -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3394a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pause(variable): # function to pause and print values in the console \n",
    "    print(\"********************************\")\n",
    "    print(f\"Debug: \\n{type(variable)}\\n\\n{variable}\\n\")\n",
    "    wait = input(\"Press Enter to continue!\")\n",
    "    print(\"********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c9d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_conditions(state, positive, negative): # function to validate if positive and negative conditions are valid at a given state\n",
    "        return positive.issubset(state) and negative.isdisjoint(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae28bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition(state, positive, negative): # function to apply the transition of the state (activate positive and deactivate negative effects)\n",
    "        return state.difference(negative).union(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "880a7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grounding_all_actions(parser): # Grounding all actions to generate every valid instantiation \n",
    "                                   # (based on the number and types of objects defined in problem.pddl)\n",
    "    \n",
    "    grounded_actions = []\n",
    "    for action in parser.actions:\n",
    "        for act in action.groundify(parser.objects, parser.types):\n",
    "            # parser.objects are all instantiated objects (e.g., crane: [a, b, c, d])\n",
    "            # parser.types are all different types of instantiated objects (e.g., crane)\n",
    "            grounded_actions.append(act)\n",
    "            \n",
    "    return grounded_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb59aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applicable_actions(state, grounded_actions): # Listing  all grounded (existing) actions that are applicable\n",
    "                                                 # at the current state\n",
    "    \n",
    "    applicable_actions = []\n",
    "    for act in grounded_actions:\n",
    "        positive = act.positive_preconditions\n",
    "        negative = act.negative_preconditions\n",
    "    \n",
    "        if validate_conditions(state, positive, negative):\n",
    "            applicable_actions.append(act) \n",
    "    \n",
    "    return applicable_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22883dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_BFS(parser, grounded_actions):\n",
    "        \n",
    "        # Parsed data (all three objects are type: frozenset i.e., immutable static objects)\n",
    "        state = parser.state # initial problem.pddl state\n",
    "        goal_pos = parser.positive_goals # goal state positive conditions\n",
    "        goal_not = parser.negative_goals # goal state negative conditions\n",
    "        \n",
    "        # Check if the goal state has been reached (no planning is required)\n",
    "        if validate_conditions(state, goal_pos, goal_not):\n",
    "            print('\\nInitial state meets the goal conditions!')\n",
    "            return []\n",
    "                               \n",
    "        # Graph Search\n",
    "        closed_set = set([state]) # we already checked if the initial state is the goal state so we consider it in the closed_set\n",
    "        frontier_set = [state, None] # frontier_set is a list of: [ state, (action that led to this state, plan that led to this state from the root) ]\n",
    "        \n",
    "        while frontier_set: # while frontier_set is not empty\n",
    "            \n",
    "            # implementing Breadth-First-Non-Informed-Search (BFS) where the visited/closed states set is served in FIFO manner\n",
    "            # since the state under consideration is popped(0) which is the oldest of the appended 'frontier' set 'new_states'\n",
    "            state = frontier_set.pop(0) # popping out (remove and assign) the first (or appended) state from the frontier_set\n",
    "            plan = frontier_set.pop(0) # popping out (remove and assign) the first (or appended) plan from the frontier_set i.e., None\n",
    "            \n",
    "            for act in grounded_actions: # iterate over all grounded actions\n",
    "                \n",
    "                if validate_conditions(state, act.positive_preconditions, act.negative_preconditions): # check if the grounded action is currently applicable\n",
    "                    new_state = state_transition(state, act.add_effects, act.del_effects)\n",
    "                    \n",
    "                    if new_state not in closed_set: # check if the new_state has not been visited/evaluated already\n",
    "                        if validate_conditions(new_state, goal_pos, goal_not): # check if the new state is the goal state\n",
    "                            \n",
    "                            full_plan = [ act ] # initialise the full plan with the last action\n",
    "                            while plan:\n",
    "                                act, plan = plan # iteratively unfolding the enveloped plan and the respective sequence of actions\n",
    "                                full_plan.insert(0, act) # populate the full_plan 0-position entry with the previous action i.e., the sequence of actions led to the goal state\n",
    "\n",
    "                            return full_plan\n",
    "                        \n",
    "                        closed_set.add(new_state) # appending (at the end of the list) the new_state (which is not the goal state)\n",
    "                        frontier_set.append(new_state) # appending (at the end of the list) the new_state (which is not the goal state)\n",
    "                        frontier_set.append((act, plan)) # appending the grounded action led to the new_state alongside with the up-to-date plan(t) = [ action(t), plan(t-1) ]\n",
    "                    \n",
    "        return None # return 'None' if the goal state has not been reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa2c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_plan(plan, verbose = True):\n",
    "    \n",
    "    print('\\n----------------------------')\n",
    "    if type(plan) is list:\n",
    "        print('Plan:')\n",
    "        for act in plan:\n",
    "            print(act if verbose else act.name + ' ' + ' '.join(act.parameters))\n",
    "    else:\n",
    "        print('No plan was found')\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c75613d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_parser(parser):\n",
    "    \n",
    "    print('\\n----------------------------')\n",
    "    print('Domain name: ' + parser.domain_name)\n",
    "    for act in parser.actions:\n",
    "        print(act)\n",
    "    print('Problem name: ' + parser.problem_name)\n",
    "    print('Objects: ' + str(parser.objects))\n",
    "    print('Types: ' + str(parser.types))\n",
    "    print('Initial State: ' + str(parser.state))\n",
    "    print('Positive goal conditions: ' + str(parser.positive_goals))\n",
    "    print('Negative goal conditions: ' + str(parser.negative_goals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92188a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plan(parser, solver='BFS'):\n",
    "    import time\n",
    "    #export_parser(parser)\n",
    "    \n",
    "    start_planner_time = time.time()\n",
    "    grounded_actions = grounding_all_actions(parser)\n",
    "\n",
    "    # Planner instantiation\n",
    "    if solver == 'BFS':\n",
    "        plan = solve_BFS(parser, grounded_actions)\n",
    "    elif solver == 'DFS':\n",
    "        print('No DFS planner found!\\nProceeding with BFS!')\n",
    "        plan = solve_BFS(parser)\n",
    "        \n",
    "    plan_time = time.time()\n",
    "\n",
    "    export_plan(plan)\n",
    "    print(solver + ' Planner Time: ' + str(plan_time-start_planner_time) + 's\\n')\n",
    "    \n",
    "    return plan, grounded_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "653108e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_goal(parser, plan, step):\n",
    "    # checking after new reached state (as the plan is being executed) whether goal has been achieved\n",
    "    \n",
    "    flag = False\n",
    "\n",
    "    if validate_conditions(parser.state, parser.positive_goals, parser.negative_goals):\n",
    "        flag = True\n",
    "        print('\\nReached state meets the goal state conditions:')\n",
    "        print(parser.state)\n",
    "        plan_length = len(plan)\n",
    "        for counter in range(step+1,plan_length): # popping out (discarding) the last plan steps which\n",
    "                                                  # were actually not executed to reach the goal\n",
    "            plan.pop(-1)\n",
    "            \n",
    "    return plan, flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5341b7b",
   "metadata": {},
   "source": [
    "#### Auxiliary functions enabling modifications in the parser objects and facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74e67961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exrtact_parser_objects(parser): # extracting the objects defined/registered in the parser\n",
    "    \n",
    "    keys = parser.objects.keys()\n",
    "    objects = []\n",
    "    objects_set = set() # empty set\n",
    "\n",
    "    for key in keys:\n",
    "        temp_list = parser.objects.get(key)\n",
    "        objects.extend(temp_list)\n",
    "        objects_set = objects_set.union(set(temp_list))\n",
    "        \n",
    "    return keys, objects, objects_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a6403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objects_check(parser, items): # check whether an item is valid/true/exists in the declared objects set\n",
    "    \n",
    "    _, _, objects_set = exrtact_parser_objects(parser)\n",
    "    # objects is a type of 'list-of-lists' and items is a value from a parser.objects.key()\n",
    "    \n",
    "    # just to randomly sample one already existing fact in the state and validate code\n",
    "    # from random import sample\n",
    "    # items_number = 1\n",
    "    # items = sample(objects, items_number)[0]\n",
    "    \n",
    "    if set(items).intersection(objects_set) == set(items):\n",
    "        flag = True # all items have been found in objects\n",
    "    else:\n",
    "        flag = False # not all items have been found in objects\n",
    "    \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dde2633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objects_modify(parser, items, items_keys, mod_action): # modify a fact accordingly (discard or add) in the currently reached state\n",
    "    \n",
    "    keys, objects, objects_set = exrtact_parser_objects(parser)\n",
    "\n",
    "    if mod_action == 'rem':\n",
    "        if objects_check(parser, items): # if the items exist in the objects dictionary of the parser\n",
    "            for item in items:\n",
    "                for key in keys:\n",
    "                    operation_rem = set(parser.objects.get(key)).difference(set([item]))                    \n",
    "                    parser.objects[key] = list(operation_rem) # discard fact from objects dictionary\n",
    "\n",
    "    elif mod_action == 'add':\n",
    "        for item in items:\n",
    "            for key in items_keys:\n",
    "                if key in keys: # checking if the coupled key of the item exists in the domain\n",
    "                    operation_add = set(parser.objects.get(key)).union(set([item]))\n",
    "                    parser.objects[key] = list(operation_add) # add fact from objects dictionary\n",
    "    \n",
    "    return parser # returning the modified parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bc51a",
   "metadata": {},
   "source": [
    "#### Domain and Problem specific functions to support the definition of rationale facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7653695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unoccupied_location(parser):\n",
    "    \n",
    "    from random import sample\n",
    "    \n",
    "    robots = parser.objects.get('robot')\n",
    "    locations = parser.objects.get('location')\n",
    "    state = parser.state\n",
    "    \n",
    "    # find the facts that refer to the 'robots' objects in the parser.state frozenset\n",
    "    occupied_locations = []\n",
    "    for fact in state:\n",
    "        for robot in robots:\n",
    "            # find the occupied_locations\n",
    "            if ('at' in fact) and (robot in fact):\n",
    "                occupied_locations.append(fact[2])\n",
    "    \n",
    "    free_locations = set(locations).difference(set(occupied_locations))\n",
    "    # select randomly the location to deploy the new robot\n",
    "    deployment_location = sample(free_locations, 1)[0]\n",
    "    \n",
    "    return deployment_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74076a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_item_location(parser, item, item_key):\n",
    "    \n",
    "    state = parser.state\n",
    "    \n",
    "    for fact in state:\n",
    "        if item_key == 'robot':\n",
    "            if ('at' in fact) and (item in fact):\n",
    "                location = fact[2]\n",
    "                \n",
    "        if item_key == 'pile':\n",
    "            if ('attached' in fact) and (item in fact):\n",
    "                location = fact[2]\n",
    "        \n",
    "        if item_key == 'crane':\n",
    "            if ('belong' in fact) and (item in fact):\n",
    "                location = fact[2]\n",
    "        \n",
    "        if item_key == 'container':\n",
    "            if ('in' in fact) and (item in fact):\n",
    "                pile = fact[2]\n",
    "                for _fact in state:\n",
    "                    if ('attached' in _fact) and (pile in fact):\n",
    "                        location = _fact[2]\n",
    "                    \n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d98da887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_robot_facts_to_remove(parser, item, item_key):\n",
    "    from random import sample\n",
    "    \n",
    "    state = parser.state\n",
    "    \n",
    "    location = find_item_location(parser, item, item_key)\n",
    "    find_robot_facts_to_remove = []\n",
    "    for fact in state:\n",
    "        if ('at' in fact) and (item in fact) and (location in fact): # unoccupying the location of the removed robot\n",
    "            find_robot_facts_to_remove.append(fact)\n",
    "            find_robot_facts_to_remove.append(('occupied', location))\n",
    "    \n",
    "    piles = parser.objects.get('pile')\n",
    "    local_piles = []\n",
    "    for fact in state: # collecting the local piles (attached to the location of the robot)\n",
    "        for pile in piles:\n",
    "            if ('attached' in fact) and (location in fact) and (pile in fact):\n",
    "                local_piles.append(pile) # searching for the piles existing at the current location of the robot\n",
    "    \n",
    "    top_containers = []\n",
    "    for fact in state: # collecting the top containers of the local piles\n",
    "        for pile in local_piles:\n",
    "            if ('top' in fact) and (pile in fact):\n",
    "                top_container = fact[1]\n",
    "                top_containers.append(top_container)\n",
    "    \n",
    "    for fact in state: # removing the unloaded robot fact (if it is unloaded)\n",
    "        if ('unloaded' in fact) and (item in fact):\n",
    "            find_robot_facts_to_remove.append(fact)\n",
    "    \n",
    "    for fact in state:\n",
    "        if ('loaded' in fact) and (item in fact): # removing the loaded robot fact (if it is loaded)\n",
    "            container = fact[2]\n",
    "            find_robot_facts_to_remove.append(fact)\n",
    "            \n",
    "            selected_entry = sample(range(len(local_piles)), 1)[0] # select randomly the pile and the respective top container\n",
    "            selected_pile = local_piles[selected_entry]\n",
    "            top_container_of_selected_pile = top_containers[selected_entry]\n",
    "            \n",
    "            find_robot_facts_to_remove.append(('on', container, top_container_of_selected_pile)) # placing the container on top of \n",
    "                                                                   # the previous top container of the\n",
    "                                                                   # randomly-selected pile at the current location \n",
    "                                                                   # of the robot\n",
    "            \n",
    "            find_robot_facts_to_remove.append(('top', container, selected_pile)) # placing the container on the top of a \n",
    "                                                                   # randomly-selected pile at the current location \n",
    "                                                                   # of the robot\n",
    "            \n",
    "    return find_robot_facts_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7d94a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_location_facts_to_remove(parser, item, key):\n",
    "    find_location_facts_to_remove = []\n",
    "    \n",
    "    return find_location_facts_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c445c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_crane_locations(parser):\n",
    "    state = parser.state\n",
    "    deployment_locations = []\n",
    "    undeployment_locations = []\n",
    "    for fact in state:\n",
    "        for location in parser.objects.get('location'):\n",
    "            if ('belong' in fact) and (location in fact):\n",
    "                undeployment_locations.append(location)\n",
    "            else:\n",
    "                deployment_locations.append(location)\n",
    "                    \n",
    "    return deployment_locations, undeployment_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92b9b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_crane_facts_to_add(parser, item, key, deployment_location):\n",
    "    find_crane_facts_to_add = []\n",
    "    \n",
    "    state = parser.state\n",
    "    \n",
    "    for fact in state:\n",
    "        if ('belong' in fact) and (deployment_location in fact): # if the location the new pile was deployed at does not already have an existing crane\n",
    "            find_crane_facts_to_add.append(('belong', 'crane', deployment_location)) # defining the crane deployment location\n",
    "            find_crane_facts_to_add.append(('empty', 'crane')) # defining the initial crane status\n",
    "    \n",
    "    return find_crane_facts_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ccbf556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_crane_facts_to_remove(parser, item, key):\n",
    "    # check if the crane is currently holding a container (if so then remove the crane and the container)\n",
    "    find_crane_facts_to_remove = []\n",
    "    \n",
    "    state = parser.state\n",
    "    \n",
    "    for fact in state:\n",
    "        if ('belong' in fact) and (item in fact):\n",
    "            find_crane_facts_to_remove.append(fact)\n",
    "            \n",
    "        if ('empty' in fact) and (item in fact):\n",
    "            find_crane_facts_to_remove.append(fact)\n",
    "            \n",
    "        if ('holding' in fact) and (item in fact):\n",
    "            container = fact[2]\n",
    "            find_crane_facts_to_remove.append(fact)\n",
    "            find_crane_facts_to_remove.extend(find_container_facts_to_remove(parser, container, 'container'))\n",
    "    \n",
    "    return find_crane_facts_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53983df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pile_facts_to_remove(parser, item, key):\n",
    "    find_pile_facts_to_remove = []\n",
    "    \n",
    "    state = parser.state\n",
    "    for fact in state:\n",
    "        if ('attached' in fact) and (item in fact):\n",
    "            location = fact[2]\n",
    "            find_pile_facts_to_remove.append(('attached', item, location))\n",
    "            \n",
    "    find_pile_facts_to_remove.extend(find_piled_containers_facts(parser, item))\n",
    "\n",
    "    return find_pile_facts_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "630a4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_piled_containers_facts(parser, pile):\n",
    "    \n",
    "    find_piled_containers_facts = []\n",
    "    \n",
    "    state = parser.state\n",
    "    piled_containers = []\n",
    "    for fact in state:\n",
    "        if ('in' in fact) and (pile in fact):\n",
    "            container = fact[1]\n",
    "            piled_containers.append(container)\n",
    "            find_piled_containers_facts.append(('in', container, pile))\n",
    "            find_piled_containers_facts.append(('equal', container, container))\n",
    "            \n",
    "        if ('top' in fact) and (pile in fact):\n",
    "            find_piled_containers_facts.append(fact)\n",
    "            \n",
    "    for fact in state:\n",
    "        for container in piled_containers:\n",
    "            if ('on' in fact) and (container in fact):\n",
    "                find_piled_containers_facts.append(fact)\n",
    "        \n",
    "    return find_piled_containers_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5d99c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_container_facts_to_add(parser, item, key):\n",
    "    \n",
    "    # check the top containers of every pile\n",
    "    # and put the specified container on top of a random selected_pile: ('top', item, selected_pile)\n",
    "    # remove ('top', previous_top, selected_pile)\n",
    "    # change the previously top container of the randomly selected pile appropriately: ('on', item, previous_top)\n",
    "    # do not forget to define the facts:\n",
    "    # ('equal', item, item)\n",
    "    # ('in', item, selected_pile)\n",
    "    from random import sample\n",
    "    \n",
    "    find_container_facts_to_remove = []\n",
    "    find_container_facts_to_add = []\n",
    "    state = parser.state\n",
    "    \n",
    "    top_containers = []\n",
    "    existing_piles = []\n",
    "    for fact in state:\n",
    "        if ('top' in fact):\n",
    "            pile = fact[2]\n",
    "            existing_piles.append(pile)\n",
    "            \n",
    "            top_container = fact[1]\n",
    "            top_containers.append(top_container)\n",
    "    \n",
    "    if existing_piles: # if there any pile exists\n",
    "        selected_entry = sample(range(0,len(existing_piles)),1)\n",
    "        selected_pile = existing_piles[selected_entry]\n",
    "        selected_top_container = top_containers[selected_entry]\n",
    "        \n",
    "        find_container_facts_to_remove.append(('top', selected_top_container, selected_pile))\n",
    "        \n",
    "        find_container_facts_to_add.append(('top', item, selected_pile))\n",
    "        find_container_facts_to_add.append(('in', item, selected_pile))\n",
    "        find_container_facts_to_add.append(('on', item, selected_top_container))\n",
    "        find_container_facts_to_add.append(('equal', item, item))\n",
    "    \n",
    "    return find_container_facts_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "970c8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_container_facts_to_remove(parser, item, key):\n",
    "    \n",
    "    find_container_facts_to_remove = []\n",
    "    find_container_facts_to_add = []\n",
    "    state = parser.state\n",
    "    \n",
    "    # e.g., for cb container\n",
    "    # ('equal', cb, cb)\n",
    "    # ('in', cb, p1)\n",
    "    # ('top', cb, p1)\n",
    "    # ('on', cc, cb) # this translated to: the 'cc' container is on top of the 'cb' container\n",
    "    # ('loaded', 'r1', 'cb') <-> ('unloaded', 'r1')\n",
    "    # ('holding', 'k1', 'cb') <-> ('empty', 'k1')\n",
    "    \n",
    "    for fact in state:\n",
    "        if ('equal' in fact) and (item in fact):\n",
    "            find_container_facts_to_remove.append(fact)\n",
    "            \n",
    "        if ('in' in fact) and (item in fact):\n",
    "            find_container_facts_to_remove.append(fact)\n",
    "            \n",
    "        if ('top' in fact) and (item in fact):\n",
    "            pile = fact[2]\n",
    "            find_container_facts_to_remove.append(fact)\n",
    "            for _fact in state:\n",
    "                if ('on' in _fact) and (item in _fact): # find the container right below the top (which is removed) one\n",
    "                    below_container = _fact[2]\n",
    "                    find_container_facts_to_add.append(('top',below_container,pile))\n",
    "                    \n",
    "        if ('on' in fact[0]) and (item in fact[1]): # the case where the item container is not on the top of a pile but somewhere\n",
    "                                                    # in the middle of the pile (on top of another container)\n",
    "            below_container = fact[2]\n",
    "            find_container_facts_to_remove.append(fact)\n",
    "            _state = list(set(state).difference(set(fact))) # temporarily excluding the first ('on', container, container) fact\n",
    "            \n",
    "            for _fact in _state:\n",
    "                if ('on' in _fact[0]) and (item in _fact[2]):\n",
    "                    top_container = _fact[1]\n",
    "                    find_container_facts_to_remove.append(_fact)\n",
    "                    find_container_facts_to_add.append(('on',top_container,below_container))\n",
    "                    \n",
    "        if ('loaded' in fact) and (item in fact): # the case where the item container is loaded on a robot\n",
    "            robot = fact[1]\n",
    "            find_container_facts_to_remove.append(fact)\n",
    "            find_container_facts_to_add.append(('unloaded', robot))\n",
    "            \n",
    "        if ('holding' in fact) and (item in fact): # the case where the item container is loaded on a crane\n",
    "            crane = fact[1]\n",
    "            find_container_facts_to_remove.append(fact)\n",
    "            find_container_facts_to_add.append(('empty', crane))\n",
    "    \n",
    "    return find_container_facts_to_remove, find_container_facts_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83bae3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_facts_interpreter(parser, items, items_keys, mod_action): # this function is a domain specific function and allows to interpret\n",
    "                                                    # the items/objects modifications to relevant facts to be incorporated\n",
    "                                                    # in the parser.state as valid ones\n",
    "    \n",
    "    # e.g., when adding a new robot:\n",
    "    # its location needs to be defined as: (at r1 l1);\n",
    "    # as well as its load status: (unloaded r1)\n",
    "    # facts in the parser.state frozenset are defined as tuples\n",
    "    from random import sample\n",
    "    \n",
    "    new_facts = []\n",
    "    obsolete_facts = []\n",
    "    \n",
    "    for key in items_keys:\n",
    "        for item in items:\n",
    "            if key == 'robot':\n",
    "                if mod_action == 'add':\n",
    "                    deployment_location = find_unoccupied_location(parser)\n",
    "                    new_facts.append(('at', item, deployment_location)) # defining the initial robot deployment location\n",
    "                    new_facts.append(('unloaded', item))                # defining the initial robot status\n",
    "                    new_facts.append(('occupied', deployment_location)) # updating the status of the location\n",
    "                    \n",
    "                elif mod_action == 'rem':\n",
    "                    obsolete_facts = find_robot_facts_to_remove(parser, item, key)\n",
    "                    \n",
    "            if key == 'location':\n",
    "                if mod_action == 'add':\n",
    "                    # add new location as the robot(s) move closer to existing map's/locations' borders (to unveal new locations)\n",
    "                    # define a visibility value to add new locations (and probably new piles and new containers) accordingly\n",
    "                    new_facts = '?????????' # ??????????????\n",
    "                    \n",
    "                elif mod_action == 'rem':\n",
    "                    # remove existing location and everything located there...???\n",
    "                    obsolete_facts = '?????????' # ??????????????\n",
    "            \n",
    "            if key == 'crane':\n",
    "                if mod_action == 'add':\n",
    "                    nocrane_locations, crane_locations = find_crane_locations(parser)\n",
    "                    if nocrane_locations:\n",
    "                        deployment_location = sample(nocrane_locations, 1) # select randomly from the locations where no crane exists\n",
    "                        new_facts = find_crane_facts_to_add(parser, item, key, deployment_location)\n",
    "                    else:\n",
    "                        print('\\nCannot deploy a new crane anywhere. Cranes already exist in every known location!')\n",
    "                    \n",
    "                elif mod_action == 'rem':\n",
    "                    obsolete_facts = find_crane_facts_to_remove(parser, item, key)\n",
    "            \n",
    "            if key == 'pile':\n",
    "                if mod_action == 'add':\n",
    "                    # add new pile at a location (stating its empty stack with a new 'pallet container')\n",
    "                    deployment_location = sample(parser.objects.get('location'),1)\n",
    "                    new_facts.append(('attached', item, deployment_location)) # defining the initial pile deployment location\n",
    "                    new_facts.append(('top', 'pallet', item)) # defining the initial pile stack status\n",
    "                    \n",
    "                    nocrane_locations, crane_locations = find_crane_locations(parser)\n",
    "                    if deployment_location in nocrane_locations:\n",
    "                        new_facts.append(('belong', 'crane', deployment_location)) # defining the crane deployment location\n",
    "                        new_facts.append(('empty', 'crane')) # defining the initial crane status\n",
    "                                        \n",
    "                elif mod_action == 'rem':\n",
    "                    # remove attached/existing pile from a location and every stacked container\n",
    "                    # (e.g., this pile has been removed/served by the logistics!)\n",
    "                    obsolete_facts = find_pile_facts_to_remove(parser, item, key)\n",
    "                    \n",
    "            if key == 'container':\n",
    "                if mod_action == 'add':\n",
    "                    new_facts = '?????' #?????????\n",
    "                    \n",
    "                elif mod_action == 'rem':\n",
    "                    obsolete_facts, new_facts = find_container_facts_to_remove(parser, item, key)\n",
    "    \n",
    "    return new_facts, obsolete_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90e52cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facts_check(parser, facts): # check whether a fact is valid/true in the currently reached state\n",
    "    \n",
    "    state = parser.state\n",
    "    # state is a type of 'frozenset' and fact is a type of triplet-'tuple'\n",
    "    \n",
    "    # just to randomly sample one already existing fact in the state and validate code\n",
    "    # from random import sample\n",
    "    # facts_number = 1\n",
    "    # facts = sample(state, facts_number)[0]\n",
    "    \n",
    "    if facts in state:\n",
    "        flag = True\n",
    "    else:\n",
    "        flag = False\n",
    "                    \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84be3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facts_modify(parser, new_facts, obsolete_facts, mod_frozenset): # modify a fact accordingly (discard or add) in the currently reached state\n",
    "    \n",
    "    if mod_frozenset == 'state':\n",
    "        my_set = set(parser.state)\n",
    "    elif mod_frozenset == 'goal':\n",
    "        my_set = set(parser.goal)\n",
    "    else:\n",
    "        print('\\nError! Non-existing parser set to modify!')\n",
    "        return parser\n",
    "    \n",
    "    new_facts = set(new_facts)\n",
    "    obsolete_facts = set(obsolete_facts)\n",
    "    \n",
    "    # state = parser.state # if you want to work with frozensets instead\n",
    "    # facts = frozenset(facts) # if you want to work with frozensets instead\n",
    "    \n",
    "    \n",
    "    #if facts_check(parser.state, facts): # check if the facts that need to be removed already exist\n",
    "    my_set = my_set.difference(obsolete_facts) # discard facts from state frozenset\n",
    "    \n",
    "    # listoffrozensets = [state, facts] # if you want to work with frozensets instead\n",
    "    # my_set = frozenset().union(*listoffrozensets) # if you want to work with frozensets instead\n",
    "    my_set = my_set.union(new_facts) # add facts in state frozenset\n",
    "    \n",
    "    if mod_frozenset == 'state':\n",
    "        # parser.state = state # if you want to work with frozensets instead\n",
    "        parser.state = frozenset(my_set)\n",
    "    elif mod_frozenset == 'goal':\n",
    "        parser.goal = set(my_set)\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d72d7",
   "metadata": {},
   "source": [
    "## Generating the initial plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52857f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Time: 0.0022292137145996094s\n",
      "\n",
      "\n",
      "----------------------------\n",
      "Plan:\n",
      "action: take\n",
      "  parameters: ('k1', 'cc', 'cb', 'p1', 'l1')\n",
      "  positive_preconditions: [['empty', 'k1'], ['belong', 'k1', 'l1'], ['top', 'cc', 'p1'], ['on', 'cc', 'cb'], ['attached', 'p1', 'l1'], ['in', 'cc', 'p1']]\n",
      "  negative_preconditions: [['equal', 'cc', 'pallet'], ['equal', 'cc', 'cb']]\n",
      "  add_effects: [['holding', 'k1', 'cc'], ['top', 'cb', 'p1']]\n",
      "  del_effects: [['empty', 'k1'], ['top', 'cc', 'p1'], ['on', 'cc', 'cb'], ['in', 'cc', 'p1']]\n",
      "\n",
      "action: load\n",
      "  parameters: ('k1', 'r1', 'cc', 'l1')\n",
      "  positive_preconditions: [['holding', 'k1', 'cc'], ['belong', 'k1', 'l1'], ['at', 'r1', 'l1'], ['unloaded', 'r1']]\n",
      "  negative_preconditions: [['equal', 'cc', 'pallet']]\n",
      "  add_effects: [['empty', 'k1'], ['loaded', 'r1', 'cc']]\n",
      "  del_effects: [['holding', 'k1', 'cc'], ['unloaded', 'r1']]\n",
      "\n",
      "action: move\n",
      "  parameters: ('r1', 'l1', 'l2')\n",
      "  positive_preconditions: [['adjacent', 'l1', 'l2'], ['at', 'r1', 'l1']]\n",
      "  negative_preconditions: [['occupied', 'l2']]\n",
      "  add_effects: [['occupied', 'l2'], ['at', 'r1', 'l2']]\n",
      "  del_effects: [['at', 'r1', 'l1'], ['occupied', 'l1']]\n",
      "\n",
      "action: unload\n",
      "  parameters: ('k2', 'r1', 'cc', 'l2')\n",
      "  positive_preconditions: [['belong', 'k2', 'l2'], ['loaded', 'r1', 'cc'], ['empty', 'k2'], ['at', 'r1', 'l2']]\n",
      "  negative_preconditions: [['equal', 'cc', 'pallet']]\n",
      "  add_effects: [['unloaded', 'r1'], ['holding', 'k2', 'cc']]\n",
      "  del_effects: [['loaded', 'r1', 'cc'], ['empty', 'k2']]\n",
      "\n",
      "action: move\n",
      "  parameters: ('r1', 'l2', 'l1')\n",
      "  positive_preconditions: [['adjacent', 'l2', 'l1'], ['at', 'r1', 'l2']]\n",
      "  negative_preconditions: [['occupied', 'l1']]\n",
      "  add_effects: [['occupied', 'l1'], ['at', 'r1', 'l1']]\n",
      "  del_effects: [['at', 'r1', 'l2'], ['occupied', 'l2']]\n",
      "\n",
      "action: put\n",
      "  parameters: ('k2', 'cc', 'pallet', 'p2', 'l2')\n",
      "  positive_preconditions: [['attached', 'p2', 'l2'], ['belong', 'k2', 'l2'], ['top', 'pallet', 'p2'], ['holding', 'k2', 'cc']]\n",
      "  negative_preconditions: [['equal', 'cc', 'pallet']]\n",
      "  add_effects: [['in', 'cc', 'p2'], ['empty', 'k2'], ['on', 'cc', 'pallet'], ['top', 'cc', 'p2']]\n",
      "  del_effects: [['top', 'pallet', 'p2'], ['holding', 'k2', 'cc']]\n",
      "\n",
      "action: take\n",
      "  parameters: ('k1', 'cb', 'ca', 'p1', 'l1')\n",
      "  positive_preconditions: [['top', 'cb', 'p1'], ['in', 'cb', 'p1'], ['empty', 'k1'], ['belong', 'k1', 'l1'], ['on', 'cb', 'ca'], ['attached', 'p1', 'l1']]\n",
      "  negative_preconditions: [['equal', 'cb', 'pallet'], ['equal', 'cb', 'ca']]\n",
      "  add_effects: [['top', 'ca', 'p1'], ['holding', 'k1', 'cb']]\n",
      "  del_effects: [['top', 'cb', 'p1'], ['empty', 'k1'], ['on', 'cb', 'ca'], ['in', 'cb', 'p1']]\n",
      "\n",
      "action: load\n",
      "  parameters: ('k1', 'r1', 'cb', 'l1')\n",
      "  positive_preconditions: [['at', 'r1', 'l1'], ['belong', 'k1', 'l1'], ['holding', 'k1', 'cb'], ['unloaded', 'r1']]\n",
      "  negative_preconditions: [['equal', 'cb', 'pallet']]\n",
      "  add_effects: [['empty', 'k1'], ['loaded', 'r1', 'cb']]\n",
      "  del_effects: [['holding', 'k1', 'cb'], ['unloaded', 'r1']]\n",
      "\n",
      "action: move\n",
      "  parameters: ('r1', 'l1', 'l2')\n",
      "  positive_preconditions: [['adjacent', 'l1', 'l2'], ['at', 'r1', 'l1']]\n",
      "  negative_preconditions: [['occupied', 'l2']]\n",
      "  add_effects: [['occupied', 'l2'], ['at', 'r1', 'l2']]\n",
      "  del_effects: [['at', 'r1', 'l1'], ['occupied', 'l1']]\n",
      "\n",
      "action: unload\n",
      "  parameters: ('k2', 'r1', 'cb', 'l2')\n",
      "  positive_preconditions: [['belong', 'k2', 'l2'], ['empty', 'k2'], ['loaded', 'r1', 'cb'], ['at', 'r1', 'l2']]\n",
      "  negative_preconditions: [['equal', 'cb', 'pallet']]\n",
      "  add_effects: [['holding', 'k2', 'cb'], ['unloaded', 'r1']]\n",
      "  del_effects: [['empty', 'k2'], ['loaded', 'r1', 'cb']]\n",
      "\n",
      "action: move\n",
      "  parameters: ('r1', 'l2', 'l1')\n",
      "  positive_preconditions: [['adjacent', 'l2', 'l1'], ['at', 'r1', 'l2']]\n",
      "  negative_preconditions: [['occupied', 'l1']]\n",
      "  add_effects: [['occupied', 'l1'], ['at', 'r1', 'l1']]\n",
      "  del_effects: [['at', 'r1', 'l2'], ['occupied', 'l2']]\n",
      "\n",
      "action: put\n",
      "  parameters: ('k2', 'cb', 'pallet', 'q2', 'l2')\n",
      "  positive_preconditions: [['attached', 'q2', 'l2'], ['holding', 'k2', 'cb'], ['belong', 'k2', 'l2'], ['top', 'pallet', 'q2']]\n",
      "  negative_preconditions: [['equal', 'cb', 'pallet']]\n",
      "  add_effects: [['in', 'cb', 'q2'], ['on', 'cb', 'pallet'], ['empty', 'k2'], ['top', 'cb', 'q2']]\n",
      "  del_effects: [['holding', 'k2', 'cb'], ['top', 'pallet', 'q2']]\n",
      "\n",
      "action: take\n",
      "  parameters: ('k1', 'ca', 'pallet', 'p1', 'l1')\n",
      "  positive_preconditions: [['top', 'ca', 'p1'], ['in', 'ca', 'p1'], ['on', 'ca', 'pallet'], ['empty', 'k1'], ['belong', 'k1', 'l1'], ['attached', 'p1', 'l1']]\n",
      "  negative_preconditions: [['equal', 'ca', 'pallet']]\n",
      "  add_effects: [['holding', 'k1', 'ca'], ['top', 'pallet', 'p1']]\n",
      "  del_effects: [['top', 'ca', 'p1'], ['empty', 'k1'], ['on', 'ca', 'pallet'], ['in', 'ca', 'p1']]\n",
      "\n",
      "action: load\n",
      "  parameters: ('k1', 'r1', 'ca', 'l1')\n",
      "  positive_preconditions: [['holding', 'k1', 'ca'], ['belong', 'k1', 'l1'], ['at', 'r1', 'l1'], ['unloaded', 'r1']]\n",
      "  negative_preconditions: [['equal', 'ca', 'pallet']]\n",
      "  add_effects: [['empty', 'k1'], ['loaded', 'r1', 'ca']]\n",
      "  del_effects: [['holding', 'k1', 'ca'], ['unloaded', 'r1']]\n",
      "\n",
      "action: move\n",
      "  parameters: ('r1', 'l1', 'l2')\n",
      "  positive_preconditions: [['adjacent', 'l1', 'l2'], ['at', 'r1', 'l1']]\n",
      "  negative_preconditions: [['occupied', 'l2']]\n",
      "  add_effects: [['occupied', 'l2'], ['at', 'r1', 'l2']]\n",
      "  del_effects: [['at', 'r1', 'l1'], ['occupied', 'l1']]\n",
      "\n",
      "action: unload\n",
      "  parameters: ('k2', 'r1', 'ca', 'l2')\n",
      "  positive_preconditions: [['belong', 'k2', 'l2'], ['loaded', 'r1', 'ca'], ['empty', 'k2'], ['at', 'r1', 'l2']]\n",
      "  negative_preconditions: [['equal', 'ca', 'pallet']]\n",
      "  add_effects: [['unloaded', 'r1'], ['holding', 'k2', 'ca']]\n",
      "  del_effects: [['loaded', 'r1', 'ca'], ['empty', 'k2']]\n",
      "\n",
      "action: put\n",
      "  parameters: ('k2', 'ca', 'cc', 'p2', 'l2')\n",
      "  positive_preconditions: [['attached', 'p2', 'l2'], ['top', 'cc', 'p2'], ['belong', 'k2', 'l2'], ['holding', 'k2', 'ca']]\n",
      "  negative_preconditions: [['equal', 'ca', 'pallet'], ['equal', 'ca', 'cc']]\n",
      "  add_effects: [['in', 'ca', 'p2'], ['empty', 'k2'], ['top', 'ca', 'p2'], ['on', 'ca', 'cc']]\n",
      "  del_effects: [['top', 'cc', 'p2'], ['holding', 'k2', 'ca']]\n",
      "\n",
      "BFS Planner Time: 1.8048100471496582s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PDDL import PDDL_Parser\n",
    "import time\n",
    "\n",
    "all_plans = []\n",
    "domain = \"examples/dwr/dwr.pddl\"\n",
    "problem = \"examples/dwr/pb1.pddl\"\n",
    "\n",
    "start_time = time.time()\n",
    "# Parser instantiation\n",
    "parser = PDDL_Parser()\n",
    "parser.parse_domain(domain)\n",
    "parser.parse_problem(problem)\n",
    "parse_time = time.time()\n",
    "print('Parse Time: ' + str(parse_time-start_time) + 's\\n')\n",
    "\n",
    "# Generate plan\n",
    "active_plan, grounded_actions = generate_plan(parser)\n",
    "all_plans.append(active_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5715d",
   "metadata": {},
   "source": [
    "## Creating a dynamic re-planning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa6a35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for advancing the system state by applying 'apply_plan_steps_to_replan' of the 'plan' action sequence\n",
    "def progress_system_state(parser, plan, grounded_actions, simulation_step, apply_plan_steps_to_replan=1):    \n",
    "    if apply_plan_steps_to_replan > len(plan):\n",
    "        apply_plan_steps_to_replan = len(plan)\n",
    "\n",
    "    if type(plan) is list:\n",
    "        for step in range(0,apply_plan_steps_to_replan):\n",
    "            act = plan[step] # applying the \"optimal\" action (according to the currently active_plan)\n",
    "            # act = sample(applicable_actions(parser.state, grounded_actions),1)[0] # selecting a random (applicable) action\n",
    "            \n",
    "            simulation_step += 1\n",
    "            \n",
    "            print('\\n**************************')\n",
    "            print(f'Simulation Step: {simulation_step}')\n",
    "            print('**************************\\n')\n",
    "            print('Applying Planned Action:')\n",
    "            print(act)\n",
    "            new_state = state_transition(parser.state, act.add_effects, act.del_effects)\n",
    "            parser.state = new_state\n",
    "            plan, goal_flag = check_goal(parser, plan, step)\n",
    "            \n",
    "            if goal_flag:\n",
    "                return parser, simulation_step, plan\n",
    "        \n",
    "        print('\\nReached state:')\n",
    "        print(parser.state)\n",
    "        \n",
    "    return parser, simulation_step, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5018e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "############################ TO BE DELETED ############################\n",
    "#######################################################################\n",
    "\n",
    "def impose_stochastic_disturbance(parser, simulation_step, type_of_disturbance='none'):\n",
    "    \n",
    "    if type_of_disturbance == 'none':\n",
    "        new_change_applied = 0\n",
    "        return parser, new_change_applied\n",
    "    else:\n",
    "        new_change_applied = 1\n",
    "    \n",
    "    ## iterate the solve(domain, problem) function, over the optimal plan states / actions / steps \n",
    "    ## changing different aspects of the deterministic environment evolution:\n",
    "    ## e.g., assume that the plan will be applied and change anything at the 2nd node/state of the plan in order to re-plan:\n",
    "    ## different initial state (consider the refined current initial state to be valid with a specific likelihood) -> use a random sampler to choose between \n",
    "                ## state_transition(state, positiveA, negativeA) and state_transition(state, positiveB, negativeB) function;\n",
    "    ## different number of same type parser.objects (simulate robot failures or new grid obstacles/blockades from accidents) -> extend parser.objects entries appropriately\n",
    "    ## different goals (simulate dynamically changing goal) -> extend / refine the goal_pos and goal_not conditions appropriately\n",
    "    # pause(parser.objects)\n",
    "    \n",
    "    while True: \n",
    "        selected_key = input(f'\\nSelect key to adjust (or \"none\" to do nothing): {parser.objects.keys()}\\n')\n",
    "        if (selected_key == 'none'):\n",
    "            return parser, new_change_applied\n",
    "        \n",
    "        if (selected_key in parser.objects.keys()):\n",
    "            break\n",
    "        else:\n",
    "            print('Wrong input. Try again!')\n",
    "\n",
    "    objects_in_key = parser.objects.get(selected_key)\n",
    "\n",
    "    while True:\n",
    "        object_adjustment_type = input(f'\\nSelect to Remove, Add objects or Continue [rem/add/none]: {adjustment_type}\\n')\n",
    "        if (object_adjustment_type == 'none'):\n",
    "            return parser, new_change_applied\n",
    "        if object_adjustment_type == 'rem' or 'add':\n",
    "            break\n",
    "        else:\n",
    "            print('Wrong input. Try again!')\n",
    "\n",
    "    if adjustment_type == 'rem':\n",
    "        while True:\n",
    "            object_to_remove = input(f'\\nSelect objects to remove: {objects_in_key}\\n')\n",
    "            if object_to_remove in objects_in_key:\n",
    "                break\n",
    "            else:\n",
    "                print('Wrong input. Try again!')\n",
    "            \n",
    "            # ???????????????????   \n",
    "            # search all objects and facts (initial state, current state, goal state) and remove any references\n",
    "            # that relate to \"object_to_remove\"\n",
    "\n",
    "    elif adjustment_type == 'add':\n",
    "            # ???????????????????   \n",
    "            # search all objects and facts (initial state, current state, goal state) and add any additional facts\n",
    "            # that relate to \"object_to_add\", e.g., if a new 'container' is added then declaring its location is also needed\n",
    "            print('elif cannot be left empty since otherwise the PY parser detects and error!')\n",
    "            \n",
    "    return parser, new_change_applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd0578e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************\n",
      "Simulation Step: 1\n",
      "**************************\n",
      "\n",
      "Applying Planned Action:\n",
      "action: take\n",
      "  parameters: ('k1', 'cc', 'cb', 'p1', 'l1')\n",
      "  positive_preconditions: [['empty', 'k1'], ['belong', 'k1', 'l1'], ['top', 'cc', 'p1'], ['on', 'cc', 'cb'], ['attached', 'p1', 'l1'], ['in', 'cc', 'p1']]\n",
      "  negative_preconditions: [['equal', 'cc', 'pallet'], ['equal', 'cc', 'cb']]\n",
      "  add_effects: [['holding', 'k1', 'cc'], ['top', 'cb', 'p1']]\n",
      "  del_effects: [['empty', 'k1'], ['top', 'cc', 'p1'], ['on', 'cc', 'cb'], ['in', 'cc', 'p1']]\n",
      "\n",
      "\n",
      "Reached state:\n",
      "frozenset({('adjacent', 'l2', 'l1'), ('in', 'ca', 'p1'), ('in', 'ce', 'q1'), ('attached', 'p2', 'l2'), ('holding', 'k1', 'cc'), ('belong', 'k1', 'l1'), ('attached', 'q2', 'l2'), ('equal', 'cd', 'cd'), ('on', 'cd', 'pallet'), ('equal', 'cb', 'cb'), ('equal', 'ca', 'ca'), ('top', 'cb', 'p1'), ('attached', 'q1', 'l1'), ('in', 'cb', 'p1'), ('top', 'pallet', 'q2'), ('on', 'cb', 'ca'), ('on', 'cf', 'ce'), ('in', 'cd', 'q1'), ('adjacent', 'l1', 'l2'), ('top', 'pallet', 'p2'), ('equal', 'pallet', 'pallet'), ('on', 'ca', 'pallet'), ('equal', 'cf', 'cf'), ('top', 'cf', 'q1'), ('in', 'cf', 'q1'), ('empty', 'k2'), ('on', 'ce', 'cd'), ('belong', 'k2', 'l2'), ('occupied', 'l1'), ('unloaded', 'r1'), ('equal', 'ce', 'ce'), ('equal', 'cc', 'cc'), ('at', 'r1', 'l1'), ('attached', 'p1', 'l1')})\n",
      "\n",
      "**************************\n",
      "Simulation Step: 2\n",
      "**************************\n",
      "\n",
      "Applying Planned Action:\n",
      "action: load\n",
      "  parameters: ('k1', 'r1', 'cc', 'l1')\n",
      "  positive_preconditions: [['holding', 'k1', 'cc'], ['belong', 'k1', 'l1'], ['at', 'r1', 'l1'], ['unloaded', 'r1']]\n",
      "  negative_preconditions: [['equal', 'cc', 'pallet']]\n",
      "  add_effects: [['empty', 'k1'], ['loaded', 'r1', 'cc']]\n",
      "  del_effects: [['holding', 'k1', 'cc'], ['unloaded', 'r1']]\n",
      "\n",
      "\n",
      "Reached state:\n",
      "frozenset({('adjacent', 'l2', 'l1'), ('in', 'ca', 'p1'), ('in', 'ce', 'q1'), ('attached', 'p2', 'l2'), ('belong', 'k1', 'l1'), ('attached', 'q2', 'l2'), ('equal', 'cd', 'cd'), ('on', 'cd', 'pallet'), ('equal', 'cb', 'cb'), ('equal', 'ca', 'ca'), ('top', 'cb', 'p1'), ('loaded', 'r1', 'cc'), ('attached', 'q1', 'l1'), ('in', 'cb', 'p1'), ('top', 'pallet', 'q2'), ('on', 'cb', 'ca'), ('on', 'cf', 'ce'), ('in', 'cd', 'q1'), ('adjacent', 'l1', 'l2'), ('top', 'pallet', 'p2'), ('equal', 'pallet', 'pallet'), ('on', 'ca', 'pallet'), ('empty', 'k1'), ('equal', 'cf', 'cf'), ('top', 'cf', 'q1'), ('in', 'cf', 'q1'), ('empty', 'k2'), ('on', 'ce', 'cd'), ('belong', 'k2', 'l2'), ('occupied', 'l1'), ('equal', 'ce', 'ce'), ('equal', 'cc', 'cc'), ('at', 'r1', 'l1'), ('attached', 'p1', 'l1')})\n",
      "\n",
      "----------------------------\n",
      "No plan was found\n",
      "BFS Planner Time: 0.047585248947143555s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "apply_steps_until_next_replan = 1 # e.g., apply applied_plan_steps_to_replan=1 step(s) of the currently active plan \n",
    "                                  # and then replan considering as an initial state the current state\n",
    "number_of_replanning_attempts = 100 # e.g., number of attempts to replan after 'apply_plan_steps_to_replan'\n",
    "simulation_step = 0                 # initial value for the total simulation step\n",
    "\n",
    "new_change_applied = 0            # flag that indicates a changes has been imposed at the current timestep (compared to previous timestep)\n",
    "number_of_replanning_attempts = min(number_of_replanning_attempts, len(active_plan)) # making sure than the replanning \n",
    "                                                                    # attempts are always less than the initial plans' length\n",
    "\n",
    "for replans in range(number_of_replanning_attempts):\n",
    "    \n",
    "    if active_plan:  # if active_plan is not empty\n",
    "        \n",
    "        parser, simulation_step, active_plan_head_used = progress_system_state(parser, active_plan, grounded_actions, simulation_step, apply_steps_until_next_replan)\n",
    "        # parser, new_change_applied = impose_stochastic_disturbance(parser, simulation_step, type_of_disturbance='none')\n",
    "        \n",
    "        if simulation_step == 2: # removing r1 robot when it is loaded (according to the initial plan)\n",
    "            new_change_applied = True\n",
    "            \n",
    "            # e.g., Add items in the current objects dictionary of the parser\n",
    "            mod_action = 'rem'\n",
    "            mod_frozenset = 'state'\n",
    "            items = ['r1']\n",
    "            items_keys = ['robot'] # used only for adding items\n",
    "            objects_modify(parser, items, items_keys, mod_action)\n",
    "\n",
    "            # e.g., Add all relevant facts (depends on the domain) for the added items in the parser.objects dictionary\n",
    "            # facts = sample(parser.state, 1)[0] # randomly selected fact from the already existing ones just for debugging\n",
    "            new_facts, obsolete_facts = domain_facts_interpreter(parser, items, items_keys, mod_action)\n",
    "            parser = facts_modify(parser, new_facts, obsolete_facts, mod_frozenset)\n",
    "        else:\n",
    "            new_change_applied = False\n",
    "        \n",
    "        if active_plan_head_used: # if active_plan_tail is not empty then goal state has been unexpectedly reached before finishing the plan\n",
    "            all_plans.pop(-1) # removing the entire plan that was most recently generated\n",
    "            all_plans.append(active_plan_head_used) # to replace it with its head/fraction that was actually used to reach goal state\n",
    "            break\n",
    "            \n",
    "        # print(f'Attempt to replan: {replans}')\n",
    "        \n",
    "        # replanning after applying actions from the previously generated plan\n",
    "        if new_change_applied:\n",
    "            active_plan, grounded_actions = generate_plan(parser)\n",
    "            all_plans.append(active_plan) # replanning after applying actions based on the previously generated plan\n",
    "        else:\n",
    "            active_plan.pop(0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ba1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
